{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell imports necessary modules for anomaly detection in HEP data.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gdown\n",
    "from zipfile import ZipFile\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Load and Preprocess the data\n",
    "    - Unzip the training sample \n",
    "    - Process data in chunks\n",
    "    - Select relevant features of the data\n",
    "    - Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-06-24 16:44:51--  https://drive.google.com/file/d/1PVQTx8l5Pdqws9-AIMLsPm0P8jslOz2r/view?usp=drive_link\n",
      "Resolving drive.google.com (drive.google.com)... 142.251.209.46, 2a00:1450:4002:411::200e\n",
      "Connecting to drive.google.com (drive.google.com)|142.251.209.46|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/html]\n",
      "Saving to: ‘dataset/train_sample.zip’\n",
      "\n",
      "dataset/train_sampl     [ <=>                ]  88,14K  --.-KB/s    in 0,02s   \n",
      "\n",
      "2024-06-24 16:44:51 (3,60 MB/s) - ‘dataset/train_sample.zip’ saved [90254]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the file ID and the output file name\n",
    "file_id = \"1PVQTx8l5Pdqws9-AIMLsPm0P8jslOz2r\"\n",
    "file_name = \"train_sample.zip\"\n",
    "\n",
    "# Construct the download URL\n",
    "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "\n",
    "# Download the file\n",
    "gdown.download(url, file_name, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadZipFile",
     "evalue": "File is not a zip file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Unzip the sample data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdataset/train_sample.zip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m zip_ref:\n\u001b[1;32m      3\u001b[0m     zip_ref\u001b[38;5;241m.\u001b[39mextractall(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset/train_sample\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_env/lib/python3.12/zipfile/__init__.py:1349\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1348\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m-> 1349\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_RealGetContents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1350\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1351\u001b[0m         \u001b[38;5;66;03m# set the modified flag so central directory gets written\u001b[39;00m\n\u001b[1;32m   1352\u001b[0m         \u001b[38;5;66;03m# even if no files are added to the archive\u001b[39;00m\n\u001b[1;32m   1353\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_didModify \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_env/lib/python3.12/zipfile/__init__.py:1416\u001b[0m, in \u001b[0;36mZipFile._RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile is not a zip file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m endrec:\n\u001b[0;32m-> 1416\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile is not a zip file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1418\u001b[0m     \u001b[38;5;28mprint\u001b[39m(endrec)\n",
      "\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file"
     ]
    }
   ],
   "source": [
    "# Unzip the sample data\n",
    "with ZipFile('dataset/train_sample.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('dataset/train_sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process data in chunks\n",
    "def process_chunks(event_prefix, chunk_size=10000):\n",
    "    hits_files = [f for f in os.listdir(event_prefix) if f.endswith('-hits.csv')]\n",
    "    truth_files = [f for f in os.listdir(event_prefix) if f.endswith('-truth.csv')]\n",
    "\n",
    "    features_list = []\n",
    "\n",
    "    for hits_file, truth_file in zip(hits_files, truth_files):\n",
    "        hits_df = pd.read_csv(os.path.join(event_prefix, hits_file), usecols=['hit_id', 'x', 'y', 'z', 'volume_id', 'layer_id', 'module_id'])\n",
    "        truth_df = pd.read_csv(os.path.join(event_prefix, truth_file), usecols=['hit_id', 'particle_id', 'tpx', 'tpy', 'tpz'])\n",
    "        \n",
    "        merged_df = pd.merge(hits_df, truth_df, on='hit_id', suffixes=('_hit', '_truth'))\n",
    "\n",
    "        features = merged_df[['x', 'y', 'z', 'tpx', 'tpy', 'tpz', 'volume_id', 'layer_id', 'module_id']]\n",
    "        features_list.append(features)\n",
    "\n",
    "        # Process in chunks to reduce memory usage\n",
    "        if len(features_list) * chunk_size > 100000:  # Arbitrary limit to process in chunks\n",
    "            features_chunk = pd.concat(features_list, ignore_index=True)\n",
    "            yield features_chunk\n",
    "            features_list = []\n",
    "\n",
    "    if features_list:\n",
    "        features_chunk = pd.concat(features_list, ignore_index=True)\n",
    "        yield features_chunk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the data in chunks\n",
    "features_list = []\n",
    "for features_chunk in process_chunks('dataset/train_sample/train_100_events'):\n",
    "    features_list.append(features_chunk)\n",
    "\n",
    "# Concatenate all chunks\n",
    "all_features = pd.concat(features_list, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>tpx</th>\n",
       "      <th>tpy</th>\n",
       "      <th>tpz</th>\n",
       "      <th>volume_id</th>\n",
       "      <th>layer_id</th>\n",
       "      <th>module_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.51915</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>-0.461990</td>\n",
       "      <td>-0.023119</td>\n",
       "      <td>-7.26105</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-7.12083</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>-0.407713</td>\n",
       "      <td>-0.100549</td>\n",
       "      <td>-8.31968</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.67258</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>-0.566050</td>\n",
       "      <td>-0.023969</td>\n",
       "      <td>-8.94242</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-11.33720</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>-0.379724</td>\n",
       "      <td>-0.023690</td>\n",
       "      <td>-7.30623</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-14.57120</td>\n",
       "      <td>-1502.5</td>\n",
       "      <td>-0.756905</td>\n",
       "      <td>0.067117</td>\n",
       "      <td>-18.88480</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          y       z       tpx       tpy       tpz  volume_id  layer_id  \\\n",
       "0  -2.51915 -1502.5 -0.461990 -0.023119  -7.26105          7         2   \n",
       "1  -7.12083 -1502.5 -0.407713 -0.100549  -8.31968          7         2   \n",
       "2  -1.67258 -1502.5 -0.566050 -0.023969  -8.94242          7         2   \n",
       "3 -11.33720 -1502.5 -0.379724 -0.023690  -7.30623          7         2   \n",
       "4 -14.57120 -1502.5 -0.756905  0.067117 -18.88480          7         2   \n",
       "\n",
       "   module_id  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop headers by resetting the index and ignoring the first row\n",
    "all_features = all_features.reset_index(drop=True)\n",
    "all_features.columns = range(all_features.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3279, -0.0070, -1.4202,  ..., -1.1444, -1.1566, -0.7123],\n",
       "        [-0.2843, -0.0233, -1.4202,  ..., -1.1444, -1.1566, -0.7123],\n",
       "        [-0.2807, -0.0040, -1.4202,  ..., -1.1444, -1.1566, -0.7123],\n",
       "        ...,\n",
       "        [-3.1056,  0.4135,  2.8956,  ...,  2.3150,  1.7786, -0.5141],\n",
       "        [-3.2991,  0.2800,  2.8956,  ...,  2.3150,  1.7786, -0.5141],\n",
       "        [-3.3021,  0.2313,  2.8956,  ...,  2.3150,  1.7786, -0.5141]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize the data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(all_features)\n",
    "features_scaled = torch.tensor(features_scaled, dtype=torch.float32)\n",
    "features_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>tpx</th>\n",
       "      <th>tpy</th>\n",
       "      <th>tpz</th>\n",
       "      <th>volume_id</th>\n",
       "      <th>layer_id</th>\n",
       "      <th>module_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.327900</td>\n",
       "      <td>-0.007043</td>\n",
       "      <td>-1.42018</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.011612</td>\n",
       "      <td>-1.144437</td>\n",
       "      <td>-1.156586</td>\n",
       "      <td>-0.712339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.284348</td>\n",
       "      <td>-0.023322</td>\n",
       "      <td>-1.42018</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.011608</td>\n",
       "      <td>-1.144437</td>\n",
       "      <td>-1.156586</td>\n",
       "      <td>-0.712339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.280662</td>\n",
       "      <td>-0.004048</td>\n",
       "      <td>-1.42018</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.011606</td>\n",
       "      <td>-1.144437</td>\n",
       "      <td>-1.156586</td>\n",
       "      <td>-0.712339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.239902</td>\n",
       "      <td>-0.038237</td>\n",
       "      <td>-1.42018</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.011612</td>\n",
       "      <td>-1.144437</td>\n",
       "      <td>-1.156586</td>\n",
       "      <td>-0.712339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.281064</td>\n",
       "      <td>-0.049678</td>\n",
       "      <td>-1.42018</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.011570</td>\n",
       "      <td>-1.144437</td>\n",
       "      <td>-1.156586</td>\n",
       "      <td>-0.712339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y        z       tpx       tpy       tpz  volume_id  \\\n",
       "0 -0.327900 -0.007043 -1.42018  0.000194  0.000201  0.011612  -1.144437   \n",
       "1 -0.284348 -0.023322 -1.42018  0.000194  0.000201  0.011608  -1.144437   \n",
       "2 -0.280662 -0.004048 -1.42018  0.000193  0.000201  0.011606  -1.144437   \n",
       "3 -0.239902 -0.038237 -1.42018  0.000194  0.000201  0.011612  -1.144437   \n",
       "4 -0.281064 -0.049678 -1.42018  0.000192  0.000202  0.011570  -1.144437   \n",
       "\n",
       "   layer_id  module_id  \n",
       "0 -1.156586  -0.712339  \n",
       "1 -1.156586  -0.712339  \n",
       "2 -1.156586  -0.712339  \n",
       "3 -1.156586  -0.712339  \n",
       "4 -1.156586  -0.712339  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(features_scaled, columns=all_features.columns)\n",
    "df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
